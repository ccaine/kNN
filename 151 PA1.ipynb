{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cindey Caine A10834042\n",
    "## CSE 151 PA1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>K = 1</th>\n",
       "      <th>K = 3</th>\n",
       "      <th>K = 9</th>\n",
       "      <th>K = 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training Error</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.0935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Validation Error</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.1030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     K = 1  K = 3  K = 9  K = 15\n",
       "0    Training Error  0.000  0.055  0.072  0.0935\n",
       "1  Validation Error  0.082  0.097  0.104  0.1030"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The K which performs best on validation data is K = 1. The test error for K = 1 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error for when K = 1 is: 0.094\n"
     ]
    }
   ],
   "source": [
    "print(\"Test error for when K = 1 is: \" + str(testError[bestK]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>K = 1</th>\n",
       "      <th>K = 3</th>\n",
       "      <th>K = 9</th>\n",
       "      <th>K = 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Projection Training Error</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Projection Validation Error</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                K = 1  K = 3   K = 9  K = 15\n",
       "0    Projection Training Error   0.00  0.194  0.2295   0.253\n",
       "1  Projection Validation Error   0.32  0.297  0.2940   0.287"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The K which performs best on projection validation data is K = 9. The test error for K = 9 is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error for when K = 9 is: 0.298\n"
     ]
    }
   ],
   "source": [
    "print(\"Test error for when K = 9 is: \" + str(testErrorM[bestKm]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The classification accuracy decreases when using the projection matrix. This is because the number of labels is reduced from 748 to 20. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Test Time</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Original Labels</td>\n",
       "      <td>209.719450</td>\n",
       "      <td>420.044135</td>\n",
       "      <td>210.667919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Projection Matrix Applied</td>\n",
       "      <td>18.236767</td>\n",
       "      <td>36.585633</td>\n",
       "      <td>18.231530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Test Time  Training Time  Validation Time\n",
       "0            Original Labels  209.719450     420.044135       210.667919\n",
       "1  Projection Matrix Applied   18.236767      36.585633        18.231530"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## However, the running time drastically changes when using the projection matrix on the original data. The algorithm takes much less time to run because it only needs to consider the distances of the 20 labels per row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTime = pd.DataFrame(data=dTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataframe of all the time taken to run the KNN algorithm in seconds\n",
    "dTime = {' ': ['Original Labels', 'Projection Matrix Applied'], 'Training Time': [trainTime,trainTimeM],\n",
    "         'Validation Time': [valTime,valTimeM],'Test Time': [testTime,testTimeM]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for displaying the Training Error/Validation Error\n",
    "d = {' ':['Training Error', 'Validation Error'], 'K = 1':[trainError[0],valError[0][1]],\n",
    "     'K = 3':[trainError[1],valError[1][1]],'K = 9':[trainError[2],valError[2][1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=d,index=None)\n",
    "df['K = 15'] = [trainError[3],valError[3][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for displaying the Training Error/Validation Error on Proj Mat\n",
    "d2 = {' ':['Projection Training Error', 'Projection Validation Error'], 'K = 1':[trainErrorM[0],valErrorM[0][1]],\n",
    "     'K = 3':[trainErrorM[1],valErrorM[1][1]],'K = 9':[trainErrorM[2],valErrorM[2][1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(data=d2,index=None)\n",
    "df2['K = 15'] = [trainErrorM[3],valErrorM[3][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from random import randint\n",
    "from numpy import linalg as LA\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "with open('../pa1train.txt') as f:\n",
    "    train = f.readlines()\n",
    "train = [x.strip() for x in train] \n",
    "\n",
    "with open('../pa1validate.txt') as f:\n",
    "    val = f.readlines()\n",
    "val = [x.strip() for x in val] \n",
    "\n",
    "with open('../pa1test.txt') as f:\n",
    "    test = f.readlines()\n",
    "test = [x.strip() for x in test] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in proj matrix and remove spacing\n",
    "with open('../projection.txt') as f:\n",
    "    proj = f.readlines()\n",
    "proj = [x.strip() for x in proj] \n",
    "\n",
    "for i in range (0,len(proj)):\n",
    "    proj[i] = proj[i].split(\" \")\n",
    "    \n",
    "for i in range(0,len(proj)):\n",
    "    proj[i] = [float(j) for j in proj[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Matrix Multiplication to creat projection matrix\n",
    "def matrixMult(data,proj):\n",
    "    # create empty lists\n",
    "    projMat = []\n",
    "    projRow = []\n",
    "    x = 0\n",
    "    for i in range (0,len(data)):\n",
    "        for k in range (0,len(proj[0])):\n",
    "            for j in range (0, len(proj)):\n",
    "                x += (data[i][j] * proj[j][k])\n",
    "            projRow.append(x)\n",
    "            x = 0\n",
    "        projMat.append(projRow)\n",
    "        projRow = []\n",
    "    return projMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(training, toPred, biggestkVal):\n",
    "    allDist = []\n",
    "    kResults = []\n",
    "\n",
    "    # calculate all the distances between vector to predict and training data\n",
    "    for i in range (0,len(training)):\n",
    "        dist = LA.norm(np.array(training[i])-np.array(toPred))\n",
    "        allDist.append((i,dist))\n",
    "    \n",
    "    # sort all values by distance\n",
    "    allDist.sort(key=lambda tup: tup[1]) \n",
    "\n",
    "    # check for ties\n",
    "    i = 0\n",
    "    while(len(kResults) != biggestkVal):\n",
    "        # if there is a tie, randomly choose one of the values\n",
    "        if(allDist[i][1] == allDist[i+1][1]):\n",
    "            coin = randint(i,i+1)\n",
    "            kResults.append(allDist[coin][0])\n",
    "        else:\n",
    "            kResults.append(allDist[i][0])\n",
    "        i += 1\n",
    "    \n",
    "    return kResults    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate predictions given training data, training labels, test data, and greatest k value\n",
    "def kNNPred(trainSet, trainL, testSet, largeK):\n",
    "    pred = []\n",
    "    totPred = []\n",
    "    for i in range (0,len(testSet)):\n",
    "        dup = 0\n",
    "    \n",
    "        # outputs largest K values of training data predictions on one test data point\n",
    "        output = KNN(trainSet,testSet[i],largeK)\n",
    "    \n",
    "        for m in range (0,len(k)):\n",
    "            # get the current k value\n",
    "            curK = k[m]\n",
    "        \n",
    "            # counts label occurences in the predictions\n",
    "            data = Counter([trainL[x] for x in output[:curK]])\n",
    "    \n",
    "            # if there is only one common label append it\n",
    "            if(len(data.most_common()) == 1):\n",
    "                pred.append(data.most_common()[0][0])\n",
    "            else:\n",
    "            # check all top common data for duplicates\n",
    "                for j in range (0,len(data.most_common())-1):\n",
    "                    # if current top count == next top count then add duplicates\n",
    "                    if(data.most_common()[j][1] == data.most_common()[j+1][1]):\n",
    "                        dup += 1\n",
    "                    else:\n",
    "                        break\n",
    "                # pick a random duplicate\n",
    "                pred.append(data.most_common()[randint(0,dup)][0])\n",
    "            dup = 0\n",
    "        totPred.append(pred)\n",
    "        pred = []\n",
    "    return totPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error given labels, predictions, and number of k values\n",
    "def calcError(labels, predictions,numK):\n",
    "    error = []\n",
    "    allCount = []\n",
    "    counter = 0\n",
    "    for j in range (0, numK):\n",
    "        for i in range (0,len(labels)):\n",
    "            if(labels[i] == predictions[i][j]):\n",
    "                counter += 1\n",
    "        allCount.append(counter)\n",
    "        counter = 0\n",
    "    for i in range (0,len(allCount)):\n",
    "        error.append((len(labels)-allCount[i])/len(labels))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty lists for data sorting\n",
    "trainData = []\n",
    "trainLabel = []\n",
    "\n",
    "valData = []\n",
    "valLabel = []\n",
    "\n",
    "testData = []\n",
    "testLabel = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spaces and split into label/data\n",
    "for i in range (0,len(train)):\n",
    "    train[i] = train[i].split(\" \")\n",
    "    trainLabel.append(train[i][784])\n",
    "    trainData.append(train[i][:784])\n",
    "\n",
    "for i in range (0,len(val)):\n",
    "    val[i] = val[i].split(\" \")\n",
    "    valLabel.append(val[i][784])\n",
    "    valData.append(val[i][:784])\n",
    "\n",
    "for i in range (0,len(test)):\n",
    "    test[i] = test[i].split(\" \")\n",
    "    testLabel.append(test[i][784])\n",
    "    testData.append(test[i][:784])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert label string to int\n",
    "trainLabel = [int(i) for i in trainLabel]\n",
    "\n",
    "valLabel = [int(i) for i in valLabel]\n",
    "\n",
    "testLabel = [int(i) for i in testLabel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data string to int\n",
    "for i in range(0,len(trainData)):\n",
    "    trainData[i] = [int(j) for j in trainData[i]]\n",
    "    \n",
    "for i in range(0,len(valData)):\n",
    "    valData[i] = [int(j) for j in valData[i]]\n",
    "    \n",
    "for i in range(0,len(testData)):\n",
    "    testData[i] = [int(j) for j in testData[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init projection matrixes\n",
    "trainProj = []\n",
    "valProj = []\n",
    "testProj = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all projection matrix mult on train/val/test data\n",
    "trainProj = matrixMult(trainData,proj)\n",
    "valProj = matrixMult(valData,proj)\n",
    "testProj = matrixMult(testData,proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of k values\n",
    "k = [1,5,9,15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Lists\n",
    "trainPred = []\n",
    "valPred = []\n",
    "testPred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with training data\n",
    "t0 = time.time() \n",
    "trainPred = kNNPred(trainData,trainLabel,trainData,15)\n",
    "t1 = time.time()\n",
    "trainTime = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainError = calcError(trainLabel,trainPred,len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.055, 0.072, 0.0935]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with validation data\n",
    "t0 = time.time() \n",
    "valPred = kNNPred(trainData,trainLabel,valData,15)\n",
    "t1 = time.time()\n",
    "valTime = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "valError = calcError(valLabel,valPred,len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best k with the lowest error\n",
    "for i in range (0,len(valError)):\n",
    "    valError[i] = (i,valError[i])\n",
    "bestK = min(valError, key = lambda t: t[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with Test data\n",
    "t0 = time.time() \n",
    "testPred = kNNPred(trainData,trainLabel,testData,15)\n",
    "t1 = time.time()\n",
    "testTime = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "testError = calcError(testLabel,testPred,len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.094"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testError[bestK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction Lists\n",
    "trainPredM = []\n",
    "valPredM = []\n",
    "testPredM = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with training data projection\n",
    "t0 = time.time() \n",
    "trainPredM = kNNPred(trainProj,trainLabel,trainProj,15)\n",
    "t1 = time.time()\n",
    "trainTimeM = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainErrorM = calcError(trainLabel,trainPredM,len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with validation data projection\n",
    "t0 = time.time() \n",
    "valPredM = kNNPred(trainProj,trainLabel,valProj,15)\n",
    "t1 = time.time()\n",
    "valTimeM = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valErrorM = calcError(valLabel,valPredM,len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32, 0.297, 0.294, 0.287]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valErrorM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best k with the lowest error\n",
    "for i in range (0,len(valErrorM)):\n",
    "    valErrorM[i] = (i,valErrorM[i])\n",
    "bestKm = min(valErrorM, key = lambda t: t[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with Test data\n",
    "t0 = time.time() \n",
    "testPredM = kNNPred(trainProj,trainLabel,testProj,15)\n",
    "t1 = time.time()\n",
    "testTimeM = t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "testErrorM = calcError(testLabel,testPredM,len(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.298"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testErrorM[bestKm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
